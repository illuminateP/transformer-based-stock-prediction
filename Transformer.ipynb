{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "199d1127-29ce-48bf-98d4-0a365c4c691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22335a1e-838e-48b6-b6b5-418816728aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('삼성전자 주식데이터2.csv', encoding='cp949')\n",
    "close = df['종가'].to_numpy(dtype=np.float64)\n",
    "volumes = df['거래량'].to_numpy(dtype=np.float64)\n",
    "open = df['시가'].to_numpy(dtype=np.float64)\n",
    "high = df['고가'].to_numpy(dtype=np.float64)\n",
    "low = df['저가'].to_numpy(dtype=np.float64)\n",
    "market_cap = df['시가총액'].to_numpy(dtype=np.float64)\n",
    "shares_outstanding = df['상장주식수'].to_numpy(dtype=np.float64)\n",
    "up_down = df['결과'].to_numpy(dtype=np.float64)     # 예측 결과값 배열\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662be7d5-3499-44f3-9733-104c0637dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 선언\n",
    "width = 20  # 특성 계산을 위한 윈도우 크기 설정\n",
    "\n",
    "result = []  # 결과를 저장할 리스트\n",
    "\n",
    "for i in range(0, len(df)-width-1):\n",
    "    close_width = close[i:i+width]  # 종가 데이터\n",
    "    volumes_width = volumes[i:i+width]  # 거래량 데이터\n",
    "    open_width = open[i:i+width]  # 시가 데이터\n",
    "    high_width = high[i:i+width]  # 고가 데이터\n",
    "    low_width = low[i:i+width]  # 저가 데이터\n",
    "    market_cap_width = market_cap[i:i+width]  # 시가총액\n",
    "    shares_outstanding_width = shares_outstanding[i:i+width]  # 상장주식수\n",
    "    \n",
    "    # 대비 (현재 종가 - 이전 종가)\n",
    "    price_diff = close_width[-1] - close_width[-2]\n",
    "    \n",
    "    # 등락률 (현재 종가와 이전 종가 비율)\n",
    "    price_change = (close_width[-1] / close_width[-2]) - 1\n",
    "    \n",
    "    result.append([\n",
    "        # 5일 이동평균\n",
    "        np.mean(close_width[-5:]),\n",
    "        \n",
    "        # 20일 이동평균\n",
    "        np.mean(close_width),\n",
    "        \n",
    "        # 5일 표준편차\n",
    "        np.std(close_width[-5:]),\n",
    "        \n",
    "        # 5일 이동평균 대비 현재 종가 비율\n",
    "        close_width[-1] / np.mean(close_width[-5:]),\n",
    "        \n",
    "        # 5일 이동평균 대비 현재 거래량 비율\n",
    "        volumes_width[-1] / np.mean(volumes_width[-5:]),\n",
    "        \n",
    "        # 볼린저 밴드 위치\n",
    "        (close_width[-1] - (np.mean(close_width) - 2 * np.std(close_width))) / (4 * np.std(close_width)),\n",
    "        \n",
    "        # Z-score : 표준화 점수\n",
    "        (close_width[-1] - np.mean(close_width[-5:])) / np.std(close_width[-5:]),\n",
    "        \n",
    "        # 가격 거래량 비율\n",
    "        np.mean(np.abs(np.diff(close_width)[-5:])) / np.mean(volumes_width[-5:]),\n",
    "        \n",
    "        # 가격 가속도\n",
    "        (close_width[-1] - close_width[-2]) - (close_width[-2] - close_width[-3]),\n",
    "        \n",
    "        # 추세 강도\n",
    "        sum(1 for i in range(1, len(close_width)) if close_width[i] > close_width[i-1]) / (len(close_width)-1),\n",
    "        \n",
    "        # 시가 대비 종가 변화율\n",
    "        (close_width[-1] - open_width[-1]) / open_width[-1],\n",
    "        \n",
    "        # 고가 대비 저가 변화율\n",
    "        (high_width[-1] - low_width[-1]) / open_width[-1],\n",
    "        \n",
    "        # 시가 대비 종가 비율\n",
    "        close_width[-1] / open_width[-1],\n",
    "        \n",
    "        # 고가 대비 저가 차이\n",
    "        high_width[-1] - low_width[-1],\n",
    "        \n",
    "        # 시가총액 대비 거래대금 비율\n",
    "        np.mean(volumes_width) / np.mean(market_cap_width),\n",
    "        \n",
    "        # 상장주식수 대비 거래량 비율\n",
    "        np.mean(volumes_width) / np.mean(shares_outstanding_width),\n",
    "        \n",
    "        # 평균 거래량 대비 변화율\n",
    "        (volumes_width[-1] - np.mean(volumes_width)) / np.mean(volumes_width),\n",
    "        \n",
    "        # 고가 대비 저가 비율\n",
    "        low_width[-1] / high_width[-1],\n",
    "\n",
    "        # 일별 종가 대비 시가 비율 (시가: open, 종가: close)\n",
    "        close_width[-1] / open_width[-1],\n",
    "\n",
    "        # 최근 5일 이동평균 대비 고가 비율\n",
    "        high_width[-1] / np.mean(close_width[-5:]),\n",
    "        \n",
    "        # 최근 5일 이동평균 대비 저가 비율\n",
    "        low_width[-1] / np.mean(close_width[-5:]),\n",
    "        \n",
    "        # 5일 거래량 변화율\n",
    "        (volumes_width[-1] - volumes_width[-5]) / volumes_width[-5],\n",
    "        \n",
    "        # 일별 고가-저가 비율\n",
    "        (high_width[-1] - low_width[-1]) / open_width[-1],\n",
    "        \n",
    "        # 5일 고가-저가 차이의 표준편차\n",
    "        np.std(np.array(high_width[-5:]) - np.array(low_width[-5:])),\n",
    "        \n",
    "        # 추세 전환 점수 (예시: 5일 이동평균 크로스오버)\n",
    "        np.mean(np.diff(close_width[-5:])) / np.mean(close_width[-5:]),\n",
    "        \n",
    "        # 가격 변동성 (5일)\n",
    "        np.std(np.diff(close_width[-5:])),\n",
    "        \n",
    "        # 등락률에 따른 변화\n",
    "        price_change,\n",
    "        \n",
    "        up_down[i+width]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82076991-2b87-4f53-b568-bce0955cb839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_result = pd.DataFrame(result, columns=['5일 이동평균', '20일 이동평균', '5일 표준편차', '5일 이동평균 대비 현재 종가 비율',\n",
    "                                           '5일 이동평균 대비 현재 거래량 비율', '볼린저 밴드 위치', 'Z-score', '가격 거래량 비율',\n",
    "                                           '가격 가속도', '추세 강도', '시가 대비 종가 변화율', '고가 대비 저가 변화율',\n",
    "                                           '시가 대비 종가 비율', '고가 대비 저가 차이', '시가총액 대비 거래 대금 비율', '상장주식수 대비 거래량 비율',\n",
    "                                           '평균 거래량 대비 변화율', '고가 대비 저가 비율', '일별 종가 대비 시가 비율', '최근 5일 이동 평균 대비 고가 비율',\n",
    "                                           '최근 5일 이동평균 대비 저가 비율', '5일 거래량 변화율', '일별 고가-저가 비율',\n",
    "                                           '5일 고가 - 저가 차이의 표준편차', '추세 전환 점수', '가격 변동성', '등락률에 따른 변화',\n",
    "                                           '예측 결과값'])\n",
    "\n",
    "df4_result.to_csv('result_A.csv', index=False, header=False, encoding='cp949')\n",
    "\n",
    "data = np.vstack(df4_result.values.astype(float))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "total_rows = data.shape[0]\n",
    "split_index = int(total_rows * 2 / 3)\n",
    "\n",
    "traindata = data[:split_index, :]\n",
    "testdata = data[split_index:, :]\n",
    "\n",
    "np.savetxt('result_train.csv', traindata, delimiter=',', fmt='%f', encoding='utf-8')\n",
    "np.savetxt('result_test.csv', testdata, delimiter=',', fmt='%f', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf662a-3d87-43fa-b2c1-4379202bbfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f379ba95-f148-475d-950b-f89fccd5f39b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "traindata = np.loadtxt('result_train.csv', delimiter=',', dtype=np.float32)\n",
    "train_images = traindata[:,0:-1]\n",
    "train_labels = traindata[:,[-1]]\n",
    "\n",
    "testdata = np.loadtxt('result_test.csv', delimiter=',', dtype=np.float32)\n",
    "test_images = testdata[:,0:-1]\n",
    "test_labels = testdata[:,[-1]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_images_scaled = scaler.fit_transform(train_images)\n",
    "test_images_scaled = scaler.transform(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de40fcf5-4811-4788-84cf-7024cca04e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 27)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d1d38c3-0083-4480-81a7-a6608dcfbf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Dense, Dropout\n",
    "\n",
    "# Transformer 블록 정의\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=ff_dim)\n",
    "        self.ffn = models.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(ff_dim)\n",
    "        ])\n",
    "        self.layer_norm1 = LayerNormalization()\n",
    "        self.layer_norm2 = LayerNormalization()\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # Multi-Head Attention\n",
    "        attention_output = self.attention(inputs, inputs)\n",
    "        attention_output = self.dropout(attention_output, training=training)\n",
    "        attention_output = self.layer_norm1(inputs + attention_output)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(attention_output)\n",
    "        ffn_output = self.dropout(ffn_output, training=training)\n",
    "        output = self.layer_norm2(attention_output + ffn_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886673e2-579f-4536-8367-4940890b545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 204ms/step - accuracy: 0.4998 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.4878 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5151 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5353 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5281 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5268 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5108 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5145 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5114 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5281 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5175 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5151 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5527 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5186 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4945 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5010 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5236 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.4893 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.5496 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5116 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5062 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5275 - loss: 0.6927 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5194 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4945 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5455 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5194 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5153 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4658 - loss: 0.6940 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5244 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4875 - loss: 0.6935 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5079 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.4941 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5125 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5043 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4967 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4960 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5420 - loss: 0.6920 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5145 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5201 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5448 - loss: 0.6918 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5375 - loss: 0.6920 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5203 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5012 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5336 - loss: 0.6921 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5129 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4984 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5218 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5418 - loss: 0.6918 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.5459 - loss: 0.6916 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5290 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5279 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5181 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4897 - loss: 0.6937 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5186 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5318 - loss: 0.6921 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5427 - loss: 0.6917 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5110 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5125 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5208 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4962 - loss: 0.6935 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4932 - loss: 0.6936 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5227 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5077 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5273 - loss: 0.6922 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5299 - loss: 0.6921 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5108 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.4873 - loss: 0.6939 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5025 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5092 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5203 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5071 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5108 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5472 - loss: 0.6913 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5416 - loss: 0.6915 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.5244 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5062 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4971 - loss: 0.6935 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5164 - loss: 0.6927 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5004 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5010 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5043 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4847 - loss: 0.6941 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5088 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4860 - loss: 0.6941 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5323 - loss: 0.6919 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5171 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5221 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5066 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4773 - loss: 0.6945 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5362 - loss: 0.6917 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5301 - loss: 0.6920 - val_accuracy: 0.4933 - val_loss: 0.6938\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4949 - loss: 0.6937 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5329 - loss: 0.6919 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5273 - loss: 0.6921 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5014 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4873 - loss: 0.6940 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5223 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5053 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5212 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6938\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5244 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6938\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "정확도: 0.4933\n",
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 119ms/step - accuracy: 0.5027 - loss: 0.6932 - val_accuracy: 0.5067 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5218 - loss: 0.6931 - val_accuracy: 0.5067 - val_loss: 0.6931\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4869 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5023 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - accuracy: 0.5366 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.5030 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5164 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5199 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.4956 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4904 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5305 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5216 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5270 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5379 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4908 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5049 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4836 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5264 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5056 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4849 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5199 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5181 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5036 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5006 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5299 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6933\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5279 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4862 - loss: 0.6935 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5036 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4867 - loss: 0.6935 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5014 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4793 - loss: 0.6937 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4986 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5231 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4843 - loss: 0.6937 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5069 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6934\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5351 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5168 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4784 - loss: 0.6939 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5275 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5257 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5251 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5134 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5047 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5225 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5468 - loss: 0.6918 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5010 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5079 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5212 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5199 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5038 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4832 - loss: 0.6939 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5251 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6935\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5257 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5064 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4938 - loss: 0.6935 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5281 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4786 - loss: 0.6941 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5090 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5305 - loss: 0.6922 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5132 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5064 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5333 - loss: 0.6920 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5062 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5090 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5095 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5299 - loss: 0.6922 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5175 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4984 - loss: 0.6934 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 70/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5247 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5112 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5147 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4875 - loss: 0.6939 - val_accuracy: 0.4933 - val_loss: 0.6936\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5127 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5069 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5440 - loss: 0.6915 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5320 - loss: 0.6920 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5255 - loss: 0.6923 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5227 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5045 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5132 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5210 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5231 - loss: 0.6924 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5116 - loss: 0.6929 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4878 - loss: 0.6939 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5266 - loss: 0.6922 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5186 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5192 - loss: 0.6925 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5040 - loss: 0.6932 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5138 - loss: 0.6928 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.4852 - loss: 0.6941 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4910 - loss: 0.6938 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5171 - loss: 0.6926 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5088 - loss: 0.6930 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5255 - loss: 0.6922 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5077 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4884 - loss: 0.6940 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5017 - loss: 0.6933 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5277 - loss: 0.6921 - val_accuracy: 0.4933 - val_loss: 0.6937\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "정확도: 0.4933\n",
      "Epoch 1/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 103ms/step - accuracy: 0.4926 - loss: 0.6931 - val_accuracy: 0.4933 - val_loss: 0.6932\n",
      "Epoch 2/100\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4531 - loss: 0.6933"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "for _ in range(5):\n",
    "    # 모델 정의\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # 입력 형태에 맞게 Reshape\n",
    "    model.add(layers.Input(shape=(27, 1)))  # (batch_size, seq_len, feature_dim) 형태로 입력\n",
    "    \n",
    "    # Transformer Block 추가\n",
    "    model.add(TransformerBlock(num_heads=4, ff_dim=64, dropout_rate=0.1))\n",
    "    \n",
    "    # 출력 부분\n",
    "    model.add(layers.Flatten())  # Transformer의 출력을 평탄화\n",
    "    model.add(layers.Dense(64, activation='relu'))  # 추가적인 Dense 레이어\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # 이진 분류 출력 (예: 0 또는 1)\n",
    "    \n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # 모델 학습\n",
    "    history = model.fit(train_images_scaled, train_labels,\n",
    "                          batch_size=64,  # 배치 크기 변경\n",
    "                          epochs=100,\n",
    "                          validation_data=(test_images_scaled, test_labels),\n",
    "                          verbose=1,\n",
    "                          shuffle=True)\n",
    "\n",
    "    # 예측\n",
    "    predicted_probs = model.predict(test_images_scaled)  # 확률 예측값 (0과 1 사이)\n",
    "    \n",
    "    # 예측 결과를 이진 값으로 변환\n",
    "    predicted_labels = (predicted_probs > 0.5).astype(int)\n",
    "\n",
    "    # 정확도 계산\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    train_accuracies.append(history.history['accuracy'])\n",
    "    val_accuracies.append(history.history['val_accuracy'])\n",
    "\n",
    "    print(f\"정확도: {accuracy:.4f}\")\n",
    "    \n",
    "    accuracies.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91da00b-c3f8-48ce-8e4e-210b72b49ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_length_train = max(len(acc) for acc in train_accuracies)\n",
    "max_length_val = max(len(acc) for acc in val_accuracies)\n",
    "\n",
    "train_accuracies_padded = [np.pad(acc, (0, max_length_train - len(acc)), 'constant') for acc in train_accuracies]\n",
    "val_accuracies_padded = [np.pad(acc, (0, max_length_val - len(acc)), 'constant') for acc in val_accuracies]\n",
    "\n",
    "train_accuracies_array = np.array(train_accuracies_padded)\n",
    "val_accuracies_array = np.array(val_accuracies_padded)\n",
    "\n",
    "mean_train_accuracy = train_accuracies_array.mean(axis=0)\n",
    "mean_val_accuracy = val_accuracies_array.mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(mean_train_accuracy, label='Average Training Accuracy', color='blue')\n",
    "plt.plot(mean_val_accuracy, label='Average Validation Accuracy', color='orange')\n",
    "plt.title('Average Model Accuracy Across Runs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40822245-33ce-41e8-95e5-e384032c472c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118b892-43fc-4374-b685-0c549d07d959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044bd82-3556-4214-b78c-301e12714908",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for _ in range(5):\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(64, activation='relu', input_shape=(27,)))  # 27개의 입력 특성\n",
    "    network.add(layers.Dense(32, activation='relu'))\n",
    "    network.add(layers.Dense(1, activation='sigmoid'))\n",
    "    network.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    history = network.fit(train_images_scaled, train_labels,\n",
    "                          batch_size=32,\n",
    "                          epochs=100,\n",
    "                          verbose=1,\n",
    "                          shuffle='batch',\n",
    "                          validation_data=(test_images_scaled, test_labels))\n",
    "\n",
    "    predict = network.predict(test_images_scaled)\n",
    "\n",
    "    predicted_labels = (predict > 0.5).astype(int)\n",
    "\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    train_accuracies.append(history.history['accuracy'])\n",
    "    val_accuracies.append(history.history['val_accuracy'])\n",
    "\n",
    "    print(f\"정확도: {accuracy:.4f}\")\n",
    "    \n",
    "    accuracies.append(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
